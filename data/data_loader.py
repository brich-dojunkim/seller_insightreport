# data/data_loader.py - ì—‘ì…€ ë°ì´í„° ë¡œë“œ ë° ê²€ì¦

import pandas as pd
import os
from datetime import datetime
import sys
sys.path.append('..')
from config import DATA_VALIDATION, ERROR_MESSAGES, SUCCESS_MESSAGES

class DataLoader:
    """ì—‘ì…€ ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ ê²€ì¦ì„ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, file_path):
        self.file_path = file_path
        self.raw_data = None
        self.validated_data = None
        
    def load_excel(self):
        """ì—‘ì…€ íŒŒì¼ ë¡œë“œ"""
        try:
            if not os.path.exists(self.file_path):
                raise FileNotFoundError(ERROR_MESSAGES['file_not_found'].format(self.file_path))
            
            # ì—‘ì…€ íŒŒì¼ ì½ê¸°
            self.raw_data = pd.read_excel(self.file_path)
            print(SUCCESS_MESSAGES['data_loaded'].format(len(self.raw_data)))
            
            return self.raw_data
            
        except Exception as e:
            print(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def validate_data_structure(self):
        """ë°ì´í„° êµ¬ì¡° ê²€ì¦"""
        if self.raw_data is None:
            print("âŒ ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return False
        
        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        missing_columns = []
        for col in DATA_VALIDATION['required_columns']:
            if col not in self.raw_data.columns:
                missing_columns.append(col)
        
        if missing_columns:
            print(ERROR_MESSAGES['missing_columns'].format(', '.join(missing_columns)))
            return False
        
        # ìµœì†Œ ë ˆì½”ë“œ ìˆ˜ í™•ì¸
        if len(self.raw_data) < DATA_VALIDATION['min_records_for_analysis']:
            print(ERROR_MESSAGES['insufficient_data'].format(
                DATA_VALIDATION['min_records_for_analysis']))
            return False
        
        print("âœ… ë°ì´í„° êµ¬ì¡° ê²€ì¦ ì™„ë£Œ")
        return True
    
    def clean_data(self):
        """ë°ì´í„° ì •ë¦¬ ë° ì „ì²˜ë¦¬"""
        if self.raw_data is None:
            return None
        
        try:
            # ë°ì´í„° ë³µì‚¬
            cleaned_data = self.raw_data.copy()
            
            # ê²°ì œì¼ ë°ì´í„° íƒ€ì… í™•ì¸ ë° ë³€í™˜
            if 'ê²°ì œì¼' in cleaned_data.columns:
                # ë¬¸ìì—´ë¡œ ë˜ì–´ ìˆëŠ” ê²½ìš° datetime ë³€í™˜ ì‹œë„
                try:
                    cleaned_data['ê²°ì œì¼'] = pd.to_datetime(cleaned_data['ê²°ì œì¼'])
                except:
                    print("âš ï¸ ê²°ì œì¼ í˜•ì‹ ë³€í™˜ ì‹¤íŒ¨, ì›ë³¸ í˜•íƒœ ìœ ì§€")
            
            # ìˆ«ìí˜• ì»¬ëŸ¼ ì •ë¦¬
            numeric_columns = ['ìƒí’ˆê°€ê²©', 'ìˆ˜ëŸ‰', 'ìƒí’ˆë³„ ì´ ì£¼ë¬¸ê¸ˆì•¡']
            for col in numeric_columns:
                if col in cleaned_data.columns:
                    # ë¬¸ìì—´ì—ì„œ ìˆ«ì ì¶”ì¶œ (ì‰¼í‘œ ì œê±° ë“±)
                    if cleaned_data[col].dtype == 'object':
                        cleaned_data[col] = pd.to_numeric(
                            cleaned_data[col].astype(str).str.replace(',', ''), 
                            errors='coerce'
                        )
                    
                    # ê²°ì¸¡ê°’ì„ 0ìœ¼ë¡œ ì²˜ë¦¬
                    cleaned_data[col] = cleaned_data[col].fillna(0)
            
            # ë¬¸ìì—´ ì»¬ëŸ¼ ì •ë¦¬ (ì•ë’¤ ê³µë°± ì œê±°)
            string_columns = ['íŒë§¤ì±„ë„', 'ì…ì ì‚¬ëª…', 'ìƒí’ˆëª…', 'ì£¼ë¬¸ìƒíƒœ']
            for col in string_columns:
                if col in cleaned_data.columns:
                    cleaned_data[col] = cleaned_data[col].astype(str).str.strip()
            
            # ì¤‘ë³µ ì œê±°
            initial_count = len(cleaned_data)
            cleaned_data = cleaned_data.drop_duplicates(subset=['ìƒí’ˆì£¼ë¬¸ë²ˆí˜¸'])
            final_count = len(cleaned_data)
            
            if initial_count != final_count:
                print(f"âœ… ì¤‘ë³µ ì œê±°: {initial_count - final_count}ê±´")
            
            self.validated_data = cleaned_data
            print("âœ… ë°ì´í„° ì •ë¦¬ ì™„ë£Œ")
            
            return self.validated_data
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ì •ë¦¬ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def get_data_summary(self):
        """ë°ì´í„° ìš”ì•½ ì •ë³´ ë°˜í™˜"""
        if self.validated_data is None:
            return None
        
        summary = {
            'total_records': len(self.validated_data),
            'date_range': {
                'start': self.validated_data['ê²°ì œì¼'].min(),
                'end': self.validated_data['ê²°ì œì¼'].max()
            },
            'companies': self.validated_data['ì…ì ì‚¬ëª…'].unique().tolist(),
            'channels': self.validated_data['íŒë§¤ì±„ë„'].unique().tolist(),
            'total_revenue': self.validated_data['ìƒí’ˆë³„ ì´ ì£¼ë¬¸ê¸ˆì•¡'].sum(),
            'columns': self.validated_data.columns.tolist()
        }
        
        return summary
    
    def filter_by_company(self, company_name):
        """íŠ¹ì • ì…ì ì‚¬ ë°ì´í„°ë§Œ í•„í„°ë§"""
        if self.validated_data is None:
            print("âŒ ê²€ì¦ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None
        
        company_data = self.validated_data[
            self.validated_data['ì…ì ì‚¬ëª…'] == company_name
        ].copy()
        
        if len(company_data) == 0:
            print(ERROR_MESSAGES['no_company_data'].format(company_name))
            return None
        
        print(SUCCESS_MESSAGES['company_filtered'].format(company_name, len(company_data)))
        return company_data
    
    def get_available_companies(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì…ì ì‚¬ ëª©ë¡ ë°˜í™˜"""
        if self.validated_data is None:
            return []
        
        companies = self.validated_data.groupby('ì…ì ì‚¬ëª…').size().sort_values(ascending=False)
        return companies.to_dict()

# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_data_loader(file_path="order_list_20250818120157_497.xlsx"):
    """ë°ì´í„° ë¡œë” í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª ë°ì´í„° ë¡œë” í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    # ë°ì´í„° ë¡œë” ì´ˆê¸°í™”
    loader = DataLoader(file_path)
    
    # 1. ì—‘ì…€ íŒŒì¼ ë¡œë“œ
    data = loader.load_excel()
    if data is None:
        return False
    
    # 2. ë°ì´í„° êµ¬ì¡° ê²€ì¦
    if not loader.validate_data_structure():
        return False
    
    # 3. ë°ì´í„° ì •ë¦¬
    cleaned_data = loader.clean_data()
    if cleaned_data is None:
        return False
    
    # 4. ë°ì´í„° ìš”ì•½
    summary = loader.get_data_summary()
    print("\nğŸ“Š ë°ì´í„° ìš”ì•½:")
    print(f"   â€¢ ì´ ë ˆì½”ë“œ: {summary['total_records']:,}ê±´")
    print(f"   â€¢ ê¸°ê°„: {summary['date_range']['start']} ~ {summary['date_range']['end']}")
    print(f"   â€¢ ì…ì ì‚¬ ìˆ˜: {len(summary['companies'])}ê°œ")
    print(f"   â€¢ íŒë§¤ì±„ë„ ìˆ˜: {len(summary['channels'])}ê°œ")
    print(f"   â€¢ ì´ ë§¤ì¶œ: â‚©{summary['total_revenue']:,.0f}")
    
    # 5. ì…ì ì‚¬ë³„ ë°ì´í„° í™•ì¸
    companies = loader.get_available_companies()
    print("\nğŸ¢ ì…ì ì‚¬ë³„ ì£¼ë¬¸ ê±´ìˆ˜:")
    for company, count in list(companies.items())[:5]:
        print(f"   â€¢ {company}: {count:,}ê±´")
    
    # 6. í¬ë ˆìŠ¤íŠ¸í• ë°ì´í„° í•„í„°ë§ í…ŒìŠ¤íŠ¸
    forestfit_data = loader.filter_by_company("í¬ë ˆìŠ¤íŠ¸í•")
    if forestfit_data is not None:
        print(f"\nâœ… í¬ë ˆìŠ¤íŠ¸í• ë°ì´í„°: {len(forestfit_data)}ê±´")
    
    print("\nğŸ‰ ë°ì´í„° ë¡œë” í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    return True

if __name__ == "__main__":
    test_data_loader()